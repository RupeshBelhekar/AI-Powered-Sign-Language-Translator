# AI-Powered Sign Language Translator - Frontend

This project is a web application that integrates real-time sign language recognition and translation into text. It utilizes a trained machine learning model to detect hand gestures and display the corresponding text in real-time.

## Features

- **Real-Time Gesture Detection**: Captures hand gestures using the webcam and processes them for recognition.
- **Gesture-to-Text Conversion**: Converts recognized gestures into text using a trained LSTM model.
- **Live Display**: Displays the recognized gestures and corresponding text overlay in real-time.
- **Web Extension for Live Captions**: Provides a Chrome extension that overlays captions on video calls, enhancing accessibility.

## Getting Started

### Prerequisites

- Node.js and npm installed on your machine.
- Access to a webcam for gesture detection.

### Installation

1. Clone the repository:
   ```
   git clone https://github.com/yourusername/AI-Powered-Sign-Language-Translator.git
   ```

2. Navigate to the frontend directory:
   ```
   cd AI-Powered-Sign-Language-Translator/frontend
   ```

3. Install the required dependencies:
   ```
   npm install
   ```

### Running the Application

To start the frontend application, run:
```
npm start
```
This will launch the application in your default web browser.

### Usage

- Allow access to your webcam when prompted.
- Perform gestures in front of the camera to see the real-time translation.

## Contributing

Contributions are welcome! Please open an issue or submit a pull request for any enhancements or bug fixes.

## License

This project is licensed under the MIT License. See the LICENSE file for details.